[10/27 07:38:44.009]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 07:38:44.009]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 4 --coco_path COCO
[10/27 07:38:44.009]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 07:38:44.010]: world size: 1
[10/27 07:38:44.010]: rank: 0
[10/27 07:38:44.010]: local_rank: 0
[10/27 07:38:44.010]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=50, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=10, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=False, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 07:39:17.228]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 07:39:17.229]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO
[10/27 07:39:17.229]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 07:39:17.230]: world size: 1
[10/27 07:39:17.230]: rank: 0
[10/27 07:39:17.230]: local_rank: 0
[10/27 07:39:17.230]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=50, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=10, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=False, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 07:39:52.078]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 07:39:52.078]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 07:39:52.079]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 07:39:52.079]: world size: 1
[10/27 07:39:52.079]: rank: 0
[10/27 07:39:52.080]: local_rank: 0
[10/27 07:39:52.080]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=50, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=10, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 07:40:53.848]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 07:40:53.848]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 07:40:53.849]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 07:40:53.849]: world size: 1
[10/27 07:40:53.850]: rank: 0
[10/27 07:40:53.850]: local_rank: 0
[10/27 07:40:53.850]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:1', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=50, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=10, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 07:40:56.121]: number of params:43472577
[10/27 07:40:56.123]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 07:43:00.832]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 07:43:00.832]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 07:43:00.833]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 07:43:00.833]: world size: 1
[10/27 07:43:00.833]: rank: 0
[10/27 07:43:00.833]: local_rank: 0
[10/27 07:43:00.834]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:1', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=50, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=10, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 07:43:03.012]: number of params:43472577
[10/27 07:43:03.014]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:06:12.191]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:06:12.192]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:06:12.192]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:06:12.192]: world size: 1
[10/27 12:06:12.192]: rank: 0
[10/27 12:06:12.193]: local_rank: 0
[10/27 12:06:12.193]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:06:14.541]: number of params:43472577
[10/27 12:06:14.543]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:08:52.080]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:08:52.080]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:08:52.081]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:08:52.081]: world size: 1
[10/27 12:08:52.081]: rank: 0
[10/27 12:08:52.081]: local_rank: 0
[10/27 12:08:52.081]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:08:54.412]: number of params:43472577
[10/27 12:08:54.414]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:10:04.482]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:10:04.482]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:10:04.484]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:10:04.484]: world size: 1
[10/27 12:10:04.484]: rank: 0
[10/27 12:10:04.484]: local_rank: 0
[10/27 12:10:04.484]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:1,2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:11:02.563]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:11:02.564]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:11:02.565]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:11:02.565]: world size: 1
[10/27 12:11:02.565]: rank: 0
[10/27 12:11:02.565]: local_rank: 0
[10/27 12:11:02.566]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:11:04.833]: number of params:43472577
[10/27 12:11:04.835]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:11:34.401]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:11:34.401]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO
[10/27 12:11:34.402]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:11:34.402]: world size: 1
[10/27 12:11:34.402]: rank: 0
[10/27 12:11:34.402]: local_rank: 0
[10/27 12:11:34.402]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=False, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:11:36.712]: number of params:43472577
[10/27 12:11:36.714]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:14:58.484]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:14:58.484]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:14:58.485]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:14:58.486]: world size: 1
[10/27 12:14:58.486]: rank: 0
[10/27 12:14:58.486]: local_rank: 0
[10/27 12:14:58.486]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:15:00.829]: number of params:43472577
[10/27 12:15:00.832]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:15:17.674]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:15:17.675]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:15:17.676]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:15:17.676]: world size: 1
[10/27 12:15:17.676]: rank: 0
[10/27 12:15:17.676]: local_rank: 0
[10/27 12:15:17.677]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:15:19.993]: number of params:43472577
[10/27 12:15:19.995]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:15:30.808]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:15:30.808]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:15:30.810]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:15:30.810]: world size: 1
[10/27 12:15:30.810]: rank: 0
[10/27 12:15:30.810]: local_rank: 0
[10/27 12:15:30.810]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:15:33.286]: number of params:43472577
[10/27 12:15:33.288]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:16:07.261]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:16:07.261]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:16:07.262]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:16:07.262]: world size: 1
[10/27 12:16:07.262]: rank: 0
[10/27 12:16:07.262]: local_rank: 0
[10/27 12:16:07.262]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:16:09.704]: number of params:43472577
[10/27 12:16:09.707]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:19:48.018]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:19:48.018]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:19:48.019]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:19:48.019]: world size: 1
[10/27 12:19:48.019]: rank: 0
[10/27 12:19:48.019]: local_rank: 0
[10/27 12:19:48.019]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda:2', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:20:25.442]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:20:25.443]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:20:25.443]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:20:25.444]: world size: 1
[10/27 12:20:25.444]: rank: 0
[10/27 12:20:25.444]: local_rank: 0
[10/27 12:20:25.444]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:20:27.904]: number of params:43472577
[10/27 12:20:27.907]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 12:22:48.217]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 12:22:48.218]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 2 --coco_path COCO --use_dn
[10/27 12:22:48.219]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 12:22:48.219]: world size: 1
[10/27 12:22:48.219]: rank: 0
[10/27 12:22:48.219]: local_rank: 0
[10/27 12:22:48.219]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=2, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 12:22:50.674]: number of params:43472577
[10/27 12:22:50.676]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 13:26:47.767]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 13:26:47.767]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 4 --coco_path COCO --use_dn
[10/27 13:26:47.768]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 13:26:47.768]: world size: 1
[10/27 13:26:47.768]: rank: 0
[10/27 13:26:47.769]: local_rank: 0
[10/27 13:26:47.769]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=4, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 13:26:50.327]: number of params:43472577
[10/27 13:26:50.329]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
[10/27 13:27:15.604]: git:
  sha: N/A, status: clean, branch: N/A

[10/27 13:27:15.604]: Command: main.py -m dn_dab_detr --output_dir logs/dn_DABDETR/R50 --batch_size 8 --coco_path COCO --use_dn
[10/27 13:27:15.605]: Full config saved to logs/dn_DABDETR/R50/config.json
[10/27 13:27:15.605]: world size: 1
[10/27 13:27:15.605]: rank: 0
[10/27 13:27:15.605]: local_rank: 0
[10/27 13:27:15.605]: args: Namespace(amp=False, aux_loss=True, backbone='resnet50', backbone_freeze_keywords=None, batch_norm_type='FrozenBatchNorm2d', batch_size=8, bbox_loss_coef=5, box_noise_scale=0.4, clip_max_norm=0.1, cls_loss_coef=1, coco_panoptic_path=None, coco_path='COCO', contrastive=False, dataset_file='coco', debug=False, dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=2048, dist_url='env://', distributed=False, drop_lr_now=False, dropout=0.0, enc_layers=6, enc_n_points=4, eos_coef=0.1, epochs=100, eval=False, find_unused_params=False, finetune_ignore=None, fix_size=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, label_noise_scale=0.2, local_rank=0, lr=0.0001, lr_backbone=1e-05, lr_drop=40, mask_loss_coef=1, masks=False, modelname='dn_dab_detr', nheads=8, note='', num_feature_levels=4, num_patterns=0, num_queries=300, num_results=300, num_select=300, num_workers=4, output_dir='logs/dn_DABDETR/R50', override_resumed_lr_drop=False, pe_temperatureH=20, pe_temperatureW=20, position_embedding='sine', pre_norm=False, pretrain_model_path=None, random_refpoints_xy=False, rank=0, remove_difficult=False, resume='', return_interm_layers=False, save_checkpoint_interval=10, save_log=False, save_results=False, scalar=5, seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, start_epoch=0, transformer_activation='prelu', two_stage=False, use_dn=True, use_lft=False, use_mqs=False, weight_decay=0.0001, world_size=1)

[10/27 13:27:18.152]: number of params:43472577
[10/27 13:27:18.156]: params:
{
  "transformer.encoder.layers.0.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.0.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.0.linear1.weight": 524288,
  "transformer.encoder.layers.0.linear1.bias": 2048,
  "transformer.encoder.layers.0.linear2.weight": 524288,
  "transformer.encoder.layers.0.linear2.bias": 256,
  "transformer.encoder.layers.0.norm1.weight": 256,
  "transformer.encoder.layers.0.norm1.bias": 256,
  "transformer.encoder.layers.0.norm2.weight": 256,
  "transformer.encoder.layers.0.norm2.bias": 256,
  "transformer.encoder.layers.0.activation.weight": 1,
  "transformer.encoder.layers.1.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.1.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.1.linear1.weight": 524288,
  "transformer.encoder.layers.1.linear1.bias": 2048,
  "transformer.encoder.layers.1.linear2.weight": 524288,
  "transformer.encoder.layers.1.linear2.bias": 256,
  "transformer.encoder.layers.1.norm1.weight": 256,
  "transformer.encoder.layers.1.norm1.bias": 256,
  "transformer.encoder.layers.1.norm2.weight": 256,
  "transformer.encoder.layers.1.norm2.bias": 256,
  "transformer.encoder.layers.1.activation.weight": 1,
  "transformer.encoder.layers.2.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.2.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.2.linear1.weight": 524288,
  "transformer.encoder.layers.2.linear1.bias": 2048,
  "transformer.encoder.layers.2.linear2.weight": 524288,
  "transformer.encoder.layers.2.linear2.bias": 256,
  "transformer.encoder.layers.2.norm1.weight": 256,
  "transformer.encoder.layers.2.norm1.bias": 256,
  "transformer.encoder.layers.2.norm2.weight": 256,
  "transformer.encoder.layers.2.norm2.bias": 256,
  "transformer.encoder.layers.2.activation.weight": 1,
  "transformer.encoder.layers.3.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.3.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.3.linear1.weight": 524288,
  "transformer.encoder.layers.3.linear1.bias": 2048,
  "transformer.encoder.layers.3.linear2.weight": 524288,
  "transformer.encoder.layers.3.linear2.bias": 256,
  "transformer.encoder.layers.3.norm1.weight": 256,
  "transformer.encoder.layers.3.norm1.bias": 256,
  "transformer.encoder.layers.3.norm2.weight": 256,
  "transformer.encoder.layers.3.norm2.bias": 256,
  "transformer.encoder.layers.3.activation.weight": 1,
  "transformer.encoder.layers.4.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.4.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.4.linear1.weight": 524288,
  "transformer.encoder.layers.4.linear1.bias": 2048,
  "transformer.encoder.layers.4.linear2.weight": 524288,
  "transformer.encoder.layers.4.linear2.bias": 256,
  "transformer.encoder.layers.4.norm1.weight": 256,
  "transformer.encoder.layers.4.norm1.bias": 256,
  "transformer.encoder.layers.4.norm2.weight": 256,
  "transformer.encoder.layers.4.norm2.bias": 256,
  "transformer.encoder.layers.4.activation.weight": 1,
  "transformer.encoder.layers.5.self_attn.in_proj_weight": 196608,
  "transformer.encoder.layers.5.self_attn.in_proj_bias": 768,
  "transformer.encoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.encoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.encoder.layers.5.linear1.weight": 524288,
  "transformer.encoder.layers.5.linear1.bias": 2048,
  "transformer.encoder.layers.5.linear2.weight": 524288,
  "transformer.encoder.layers.5.linear2.bias": 256,
  "transformer.encoder.layers.5.norm1.weight": 256,
  "transformer.encoder.layers.5.norm1.bias": 256,
  "transformer.encoder.layers.5.norm2.weight": 256,
  "transformer.encoder.layers.5.norm2.bias": 256,
  "transformer.encoder.layers.5.activation.weight": 1,
  "transformer.encoder.query_scale.layers.0.weight": 65536,
  "transformer.encoder.query_scale.layers.0.bias": 256,
  "transformer.encoder.query_scale.layers.1.weight": 65536,
  "transformer.encoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.layers.0.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.0.sa_v_proj.bias": 256,
  "transformer.decoder.layers.0.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.norm1.weight": 256,
  "transformer.decoder.layers.0.norm1.bias": 256,
  "transformer.decoder.layers.0.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.0.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.0.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_v_proj.bias": 256,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.0.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.0.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.0.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.0.linear1.weight": 524288,
  "transformer.decoder.layers.0.linear1.bias": 2048,
  "transformer.decoder.layers.0.linear2.weight": 524288,
  "transformer.decoder.layers.0.linear2.bias": 256,
  "transformer.decoder.layers.0.norm2.weight": 256,
  "transformer.decoder.layers.0.norm2.bias": 256,
  "transformer.decoder.layers.0.norm3.weight": 256,
  "transformer.decoder.layers.0.norm3.bias": 256,
  "transformer.decoder.layers.0.activation.weight": 1,
  "transformer.decoder.layers.1.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.1.sa_v_proj.bias": 256,
  "transformer.decoder.layers.1.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.norm1.weight": 256,
  "transformer.decoder.layers.1.norm1.bias": 256,
  "transformer.decoder.layers.1.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.1.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.1.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_v_proj.bias": 256,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.1.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.1.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.1.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.1.linear1.weight": 524288,
  "transformer.decoder.layers.1.linear1.bias": 2048,
  "transformer.decoder.layers.1.linear2.weight": 524288,
  "transformer.decoder.layers.1.linear2.bias": 256,
  "transformer.decoder.layers.1.norm2.weight": 256,
  "transformer.decoder.layers.1.norm2.bias": 256,
  "transformer.decoder.layers.1.norm3.weight": 256,
  "transformer.decoder.layers.1.norm3.bias": 256,
  "transformer.decoder.layers.1.activation.weight": 1,
  "transformer.decoder.layers.2.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.2.sa_v_proj.bias": 256,
  "transformer.decoder.layers.2.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.norm1.weight": 256,
  "transformer.decoder.layers.2.norm1.bias": 256,
  "transformer.decoder.layers.2.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.2.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.2.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_v_proj.bias": 256,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.2.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.2.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.2.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.2.linear1.weight": 524288,
  "transformer.decoder.layers.2.linear1.bias": 2048,
  "transformer.decoder.layers.2.linear2.weight": 524288,
  "transformer.decoder.layers.2.linear2.bias": 256,
  "transformer.decoder.layers.2.norm2.weight": 256,
  "transformer.decoder.layers.2.norm2.bias": 256,
  "transformer.decoder.layers.2.norm3.weight": 256,
  "transformer.decoder.layers.2.norm3.bias": 256,
  "transformer.decoder.layers.2.activation.weight": 1,
  "transformer.decoder.layers.3.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.3.sa_v_proj.bias": 256,
  "transformer.decoder.layers.3.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.norm1.weight": 256,
  "transformer.decoder.layers.3.norm1.bias": 256,
  "transformer.decoder.layers.3.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.3.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.3.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_v_proj.bias": 256,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.3.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.3.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.3.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.3.linear1.weight": 524288,
  "transformer.decoder.layers.3.linear1.bias": 2048,
  "transformer.decoder.layers.3.linear2.weight": 524288,
  "transformer.decoder.layers.3.linear2.bias": 256,
  "transformer.decoder.layers.3.norm2.weight": 256,
  "transformer.decoder.layers.3.norm2.bias": 256,
  "transformer.decoder.layers.3.norm3.weight": 256,
  "transformer.decoder.layers.3.norm3.bias": 256,
  "transformer.decoder.layers.3.activation.weight": 1,
  "transformer.decoder.layers.4.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.4.sa_v_proj.bias": 256,
  "transformer.decoder.layers.4.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.norm1.weight": 256,
  "transformer.decoder.layers.4.norm1.bias": 256,
  "transformer.decoder.layers.4.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.4.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.4.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_v_proj.bias": 256,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.4.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.4.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.4.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.4.linear1.weight": 524288,
  "transformer.decoder.layers.4.linear1.bias": 2048,
  "transformer.decoder.layers.4.linear2.weight": 524288,
  "transformer.decoder.layers.4.linear2.bias": 256,
  "transformer.decoder.layers.4.norm2.weight": 256,
  "transformer.decoder.layers.4.norm2.bias": 256,
  "transformer.decoder.layers.4.norm3.weight": 256,
  "transformer.decoder.layers.4.norm3.bias": 256,
  "transformer.decoder.layers.4.activation.weight": 1,
  "transformer.decoder.layers.5.sa_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_qpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_qpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.sa_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.sa_v_proj.weight": 65536,
  "transformer.decoder.layers.5.sa_v_proj.bias": 256,
  "transformer.decoder.layers.5.self_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.self_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.norm1.weight": 256,
  "transformer.decoder.layers.5.norm1.bias": 256,
  "transformer.decoder.layers.5.ca_qcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kcontent_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kcontent_proj.bias": 256,
  "transformer.decoder.layers.5.ca_kpos_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_kpos_proj.bias": 256,
  "transformer.decoder.layers.5.ca_v_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_v_proj.bias": 256,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.weight": 65536,
  "transformer.decoder.layers.5.ca_qpos_sine_proj.bias": 256,
  "transformer.decoder.layers.5.cross_attn.out_proj.weight": 65536,
  "transformer.decoder.layers.5.cross_attn.out_proj.bias": 256,
  "transformer.decoder.layers.5.linear1.weight": 524288,
  "transformer.decoder.layers.5.linear1.bias": 2048,
  "transformer.decoder.layers.5.linear2.weight": 524288,
  "transformer.decoder.layers.5.linear2.bias": 256,
  "transformer.decoder.layers.5.norm2.weight": 256,
  "transformer.decoder.layers.5.norm2.bias": 256,
  "transformer.decoder.layers.5.norm3.weight": 256,
  "transformer.decoder.layers.5.norm3.bias": 256,
  "transformer.decoder.layers.5.activation.weight": 1,
  "transformer.decoder.norm.weight": 256,
  "transformer.decoder.norm.bias": 256,
  "transformer.decoder.query_scale.layers.0.weight": 65536,
  "transformer.decoder.query_scale.layers.0.bias": 256,
  "transformer.decoder.query_scale.layers.1.weight": 65536,
  "transformer.decoder.query_scale.layers.1.bias": 256,
  "transformer.decoder.ref_point_head.layers.0.weight": 131072,
  "transformer.decoder.ref_point_head.layers.0.bias": 256,
  "transformer.decoder.ref_point_head.layers.1.weight": 65536,
  "transformer.decoder.ref_point_head.layers.1.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.0.weight": 65536,
  "transformer.decoder.ref_anchor_head.layers.0.bias": 256,
  "transformer.decoder.ref_anchor_head.layers.1.weight": 512,
  "transformer.decoder.ref_anchor_head.layers.1.bias": 2,
  "transformer.decoder.bbox_embed.layers.0.weight": 65536,
  "transformer.decoder.bbox_embed.layers.0.bias": 256,
  "transformer.decoder.bbox_embed.layers.1.weight": 65536,
  "transformer.decoder.bbox_embed.layers.1.bias": 256,
  "transformer.decoder.bbox_embed.layers.2.weight": 1024,
  "transformer.decoder.bbox_embed.layers.2.bias": 4,
  "class_embed.weight": 23296,
  "class_embed.bias": 91,
  "label_enc.weight": 23460,
  "refpoint_embed.weight": 1200,
  "input_proj.weight": 524288,
  "input_proj.bias": 256,
  "backbone.0.body.layer2.0.conv1.weight": 32768,
  "backbone.0.body.layer2.0.conv2.weight": 147456,
  "backbone.0.body.layer2.0.conv3.weight": 65536,
  "backbone.0.body.layer2.0.downsample.0.weight": 131072,
  "backbone.0.body.layer2.1.conv1.weight": 65536,
  "backbone.0.body.layer2.1.conv2.weight": 147456,
  "backbone.0.body.layer2.1.conv3.weight": 65536,
  "backbone.0.body.layer2.2.conv1.weight": 65536,
  "backbone.0.body.layer2.2.conv2.weight": 147456,
  "backbone.0.body.layer2.2.conv3.weight": 65536,
  "backbone.0.body.layer2.3.conv1.weight": 65536,
  "backbone.0.body.layer2.3.conv2.weight": 147456,
  "backbone.0.body.layer2.3.conv3.weight": 65536,
  "backbone.0.body.layer3.0.conv1.weight": 131072,
  "backbone.0.body.layer3.0.conv2.weight": 589824,
  "backbone.0.body.layer3.0.conv3.weight": 262144,
  "backbone.0.body.layer3.0.downsample.0.weight": 524288,
  "backbone.0.body.layer3.1.conv1.weight": 262144,
  "backbone.0.body.layer3.1.conv2.weight": 589824,
  "backbone.0.body.layer3.1.conv3.weight": 262144,
  "backbone.0.body.layer3.2.conv1.weight": 262144,
  "backbone.0.body.layer3.2.conv2.weight": 589824,
  "backbone.0.body.layer3.2.conv3.weight": 262144,
  "backbone.0.body.layer3.3.conv1.weight": 262144,
  "backbone.0.body.layer3.3.conv2.weight": 589824,
  "backbone.0.body.layer3.3.conv3.weight": 262144,
  "backbone.0.body.layer3.4.conv1.weight": 262144,
  "backbone.0.body.layer3.4.conv2.weight": 589824,
  "backbone.0.body.layer3.4.conv3.weight": 262144,
  "backbone.0.body.layer3.5.conv1.weight": 262144,
  "backbone.0.body.layer3.5.conv2.weight": 589824,
  "backbone.0.body.layer3.5.conv3.weight": 262144,
  "backbone.0.body.layer4.0.conv1.weight": 524288,
  "backbone.0.body.layer4.0.conv2.weight": 2359296,
  "backbone.0.body.layer4.0.conv3.weight": 1048576,
  "backbone.0.body.layer4.0.downsample.0.weight": 2097152,
  "backbone.0.body.layer4.1.conv1.weight": 1048576,
  "backbone.0.body.layer4.1.conv2.weight": 2359296,
  "backbone.0.body.layer4.1.conv3.weight": 1048576,
  "backbone.0.body.layer4.2.conv1.weight": 1048576,
  "backbone.0.body.layer4.2.conv2.weight": 2359296,
  "backbone.0.body.layer4.2.conv3.weight": 1048576
}
